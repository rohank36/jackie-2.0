{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9Cj+crehS5bLONiY+RqJs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohank36/jackie-2.0/blob/main/jackie_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Fn9G-0UKCFHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7fe8d6e-3d6f-46c2-baf0-713c3a14f6df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradientai\n",
            "  Downloading gradientai-1.9.1-py3-none-any.whl (353 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.6/353.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aenum>=3.1.11 (from gradientai)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<2.0.0,>=1.10.5 (from gradientai)\n",
            "  Downloading pydantic-1.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.0.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0,>=1.10.5->gradientai) (4.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->gradientai) (1.16.0)\n",
            "Installing collected packages: aenum, pydantic, gradientai\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.4\n",
            "    Uninstalling pydantic-2.6.4:\n",
            "      Successfully uninstalled pydantic-2.6.4\n",
            "Successfully installed aenum-3.1.15 gradientai-1.9.1 pydantic-1.10.15\n"
          ]
        }
      ],
      "source": [
        "!pip install gradientai --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GRADIENT_ACCESS_TOKEN'] = \"\"\n",
        "os.environ['GRADIENT_WORKSPACE_ID'] = \"\""
      ],
      "metadata": {
        "id": "pjuOpBYdCkZJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "from gradientai import Gradient\n",
        "\n",
        "path_to_csv_file = \"/content/nytcrosswords.csv\""
      ],
      "metadata": {
        "id": "0fAfWIwKCmpe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Parsing data...\")\n",
        "rows_to_keep = []\n",
        "with open(path_to_csv_file, \"r\", encoding=\"utf-8-sig\", errors=\"replace\") as f:\n",
        "    reader = csv.DictReader(f, delimiter=\",\")\n",
        "    for row in reader:\n",
        "        # Extracting input (clue) and output (word) from the row\n",
        "        clue = row[\"Clue\"]\n",
        "        word = row[\"Word\"]\n",
        "        rows_to_keep.append({\"clue\": clue, \"word\": word})\n",
        "\n",
        "lines = []\n",
        "for row in rows_to_keep:\n",
        "    clue = row[\"clue\"].replace('\"', '\\\\\"')\n",
        "    word = row[\"word\"].replace('\"', '\\\\\"')\n",
        "\n",
        "    # Constructing the input/output sequence\n",
        "    start_str = \"<s>### Input:\\n\"\n",
        "    mid_str = '''\\n\\n### Response:\\n'''\n",
        "    end_str = '''</s>'''\n",
        "    total_line = start_str + clue + mid_str + word + end_str\n",
        "    obj = {\n",
        "        \"inputs\": total_line\n",
        "    }\n",
        "    lines.append(obj)\n",
        "\n",
        "print(f\"Generated {len(lines)} lines to fine-tune\")\n",
        "print(f\"Example training line: {lines[0]}\")\n",
        "\n",
        "lines_per_chunk = 20\n",
        "all_chunks = []\n",
        "for line in lines:\n",
        "    if len(all_chunks) == 0 or len(all_chunks[-1]) == lines_per_chunk:\n",
        "        all_chunks.append([])\n",
        "    all_chunks[-1].append(line)\n",
        "\n",
        "# Limiting to 100 chunks\n",
        "all_chunks = all_chunks[:100]\n",
        "\n",
        "print(f\"\\nFine-tuning model adapter\")\n",
        "gradient = Gradient()\n",
        "base = gradient.get_base_model(base_model_slug=\"nous-hermes2\")\n",
        "my_adapter = base.create_model_adapter(name=\"rohanbot\")\n",
        "print(f\"Created model with ID {my_adapter.id}\")\n",
        "for i in range(len(all_chunks)):\n",
        "    try:\n",
        "        print(f\"Fine-tuning chunk {i} of {len(all_chunks) - 1}\")\n",
        "        my_adapter.fine_tune(samples=all_chunks[i])\n",
        "    except Exception as error:\n",
        "        try:\n",
        "            error_pieces = str(error).split(\"\\n\")\n",
        "            if len(error_pieces) > 1:\n",
        "                print(f\"*** Error processing chunk {i}: {error_pieces[0]} {error_pieces[1]}\")\n",
        "            else:\n",
        "                print(f\"*** Unknown error on chunk {i}: {error}\")\n",
        "        except KeyboardInterrupt:\n",
        "            break\n",
        "        except Exception as inner_error:\n",
        "            print(inner_error)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVglVYK3DSiI",
        "outputId": "0ee5a134-2c22-4bef-fac6-3271e60b632d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing data...\n",
            "Generated 781573 lines to fine-tune\n",
            "Example training line: {'inputs': '<s>### Input:\\nAction done while saying \\\\\"Good dog\\\\\"\\n\\n### Response:\\nPAT</s>'}\n",
            "\n",
            "Fine-tuning model adapter\n",
            "Created model with ID ada699a3-172f-41fd-8b79-24261985be00_model_adapter\n",
            "Fine-tuning chunk 0 of 99\n",
            "Fine-tuning chunk 1 of 99\n",
            "Fine-tuning chunk 2 of 99\n",
            "Fine-tuning chunk 3 of 99\n",
            "Fine-tuning chunk 4 of 99\n",
            "Fine-tuning chunk 5 of 99\n",
            "Fine-tuning chunk 6 of 99\n",
            "Fine-tuning chunk 7 of 99\n",
            "Fine-tuning chunk 8 of 99\n",
            "Fine-tuning chunk 9 of 99\n",
            "Fine-tuning chunk 10 of 99\n",
            "Fine-tuning chunk 11 of 99\n",
            "Fine-tuning chunk 12 of 99\n",
            "Fine-tuning chunk 13 of 99\n",
            "Fine-tuning chunk 14 of 99\n",
            "Fine-tuning chunk 15 of 99\n",
            "Fine-tuning chunk 16 of 99\n",
            "Fine-tuning chunk 17 of 99\n",
            "Fine-tuning chunk 18 of 99\n",
            "Fine-tuning chunk 19 of 99\n",
            "Fine-tuning chunk 20 of 99\n",
            "Fine-tuning chunk 21 of 99\n",
            "Fine-tuning chunk 22 of 99\n",
            "Fine-tuning chunk 23 of 99\n",
            "Fine-tuning chunk 24 of 99\n",
            "Fine-tuning chunk 25 of 99\n",
            "Fine-tuning chunk 26 of 99\n",
            "Fine-tuning chunk 27 of 99\n",
            "Fine-tuning chunk 28 of 99\n",
            "Fine-tuning chunk 29 of 99\n",
            "Fine-tuning chunk 30 of 99\n",
            "Fine-tuning chunk 31 of 99\n",
            "Fine-tuning chunk 32 of 99\n",
            "Fine-tuning chunk 33 of 99\n",
            "Fine-tuning chunk 34 of 99\n",
            "Fine-tuning chunk 35 of 99\n",
            "Fine-tuning chunk 36 of 99\n",
            "Fine-tuning chunk 37 of 99\n",
            "Fine-tuning chunk 38 of 99\n",
            "Fine-tuning chunk 39 of 99\n",
            "Fine-tuning chunk 40 of 99\n",
            "Fine-tuning chunk 41 of 99\n",
            "Fine-tuning chunk 42 of 99\n",
            "Fine-tuning chunk 43 of 99\n",
            "Fine-tuning chunk 44 of 99\n",
            "Fine-tuning chunk 45 of 99\n",
            "Fine-tuning chunk 46 of 99\n",
            "Fine-tuning chunk 47 of 99\n",
            "Fine-tuning chunk 48 of 99\n",
            "Fine-tuning chunk 49 of 99\n",
            "Fine-tuning chunk 50 of 99\n",
            "Fine-tuning chunk 51 of 99\n",
            "Fine-tuning chunk 52 of 99\n",
            "Fine-tuning chunk 53 of 99\n",
            "Fine-tuning chunk 54 of 99\n",
            "Fine-tuning chunk 55 of 99\n",
            "Fine-tuning chunk 56 of 99\n",
            "Fine-tuning chunk 57 of 99\n",
            "Fine-tuning chunk 58 of 99\n",
            "Fine-tuning chunk 59 of 99\n",
            "Fine-tuning chunk 60 of 99\n",
            "Fine-tuning chunk 61 of 99\n",
            "Fine-tuning chunk 62 of 99\n",
            "Fine-tuning chunk 63 of 99\n",
            "Fine-tuning chunk 64 of 99\n",
            "Fine-tuning chunk 65 of 99\n",
            "Fine-tuning chunk 66 of 99\n",
            "Fine-tuning chunk 67 of 99\n",
            "Fine-tuning chunk 68 of 99\n",
            "Fine-tuning chunk 69 of 99\n",
            "Fine-tuning chunk 70 of 99\n",
            "Fine-tuning chunk 71 of 99\n",
            "Fine-tuning chunk 72 of 99\n",
            "Fine-tuning chunk 73 of 99\n",
            "Fine-tuning chunk 74 of 99\n",
            "Fine-tuning chunk 75 of 99\n",
            "Fine-tuning chunk 76 of 99\n",
            "Fine-tuning chunk 77 of 99\n",
            "Fine-tuning chunk 78 of 99\n",
            "Fine-tuning chunk 79 of 99\n",
            "Fine-tuning chunk 80 of 99\n",
            "Fine-tuning chunk 81 of 99\n",
            "Fine-tuning chunk 82 of 99\n",
            "Fine-tuning chunk 83 of 99\n",
            "Fine-tuning chunk 84 of 99\n",
            "Fine-tuning chunk 85 of 99\n",
            "Fine-tuning chunk 86 of 99\n",
            "Fine-tuning chunk 87 of 99\n",
            "Fine-tuning chunk 88 of 99\n",
            "Fine-tuning chunk 89 of 99\n",
            "Fine-tuning chunk 90 of 99\n",
            "Fine-tuning chunk 91 of 99\n",
            "Fine-tuning chunk 92 of 99\n",
            "Fine-tuning chunk 93 of 99\n",
            "Fine-tuning chunk 94 of 99\n",
            "Fine-tuning chunk 95 of 99\n",
            "Fine-tuning chunk 96 of 99\n",
            "Fine-tuning chunk 97 of 99\n",
            "Fine-tuning chunk 98 of 99\n",
            "Fine-tuning chunk 99 of 99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if your colab instance gets deleted, you can run this to get the model names\n",
        "gradient = Gradient()\n",
        "# if necessary, go back and find your previously created models and their IDs\n",
        "old_models = gradient.list_models(only_base=False)\n",
        "for model in old_models:\n",
        "  if hasattr(model, \"name\"):\n",
        "    print(f\"{model.name}: {model.id}\")"
      ],
      "metadata": {
        "id": "yNurF0yVDaX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "role_play_prompt = \"You are an elite crossword bot\"\n",
        "query = \"One of 14 on a roly-poly bug\"\n",
        "templated_query = f\"<s>### Instruction:\\n{role_play_prompt}\\n\\n###Input:\\n{query}\\n\\n### Response:\\n\"\n",
        "response = my_adapter.complete(query=templated_query, max_generated_token_count=500)\n",
        "print(f\"> {query}\\n> {response.generated_output}\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjME5dMSDaxy",
        "outputId": "d91530e7-990a-470f-b8d6-960b688d832b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> One of 14 on a roly-poly bug\n",
            "> TENPIN\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_adapter.delete()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "ItMVabFCDeQe",
        "outputId": "64e71382-7de0-4374-95f6-036027546581"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundException",
          "evalue": "(404)\nReason: Not Found\nHTTP response headers: HTTPHeaderDict({'strict-transport-security': 'max-age=63072000; includeSubDomains; preload', 'referrer-policy': 'no-referrer', 'x-content-type-options': 'nosniff', 'x-download-options': 'noopen', 'x-frame-options': 'SAMEORIGIN', 'x-xss-protection': '1; mode=block', 'content-type': 'application/json; charset=utf-8', 'etag': '\"cnneatxz1cu\"', 'vary': 'Accept-Encoding', 'X-Cloud-Trace-Context': '82f082f2dff43a19b291a6f5f4147d9a;o=1', 'Date': 'Thu, 11 Apr 2024 03:08:28 GMT', 'Server': 'Google Frontend', 'Content-Length': '30', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\nHTTP response body: {\"message\":\"Model not found.\"}\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-531dc20bc872>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradientai/_model_adapter.py\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         self._api_instance.delete_model(\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_gradient_workspace_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workspace_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/decorator.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/decorator.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/decorator.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradientai/openapi/client/api/models_api.py\u001b[0m in \u001b[0;36mdelete_model\u001b[0;34m(self, id, x_gradient_workspace_id, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_preload_content'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error! Please call the delete_model_with_http_info method with `_preload_content` instead and obtain raw data from ApiResponse.raw_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_model_with_http_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_gradient_workspace_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: E501\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mvalidate_arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/decorator.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/decorator.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/decorator.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradientai/openapi/client/api/models_api.py\u001b[0m in \u001b[0;36mdelete_model_with_http_info\u001b[0;34m(self, id, x_gradient_workspace_id, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m         }\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         return self.api_client.call_api(\n\u001b[0m\u001b[1;32m    506\u001b[0m             \u001b[0;34m'/models/{id}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DELETE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0m_path_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradientai/openapi/client/api_client.py\u001b[0m in \u001b[0;36mcall_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_types_map, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _request_auth)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \"\"\"\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0masync_req\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             return self.__call_api(resource_path, method,\n\u001b[0m\u001b[1;32m    411\u001b[0m                                    \u001b[0mpath_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                                    \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradientai/openapi/client/api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_types_map, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _request_auth)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradientai/openapi/client/api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_types_map, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _request_auth)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;31m# perform request and return response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             response_data = self.request(\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradientai/openapi/client/api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    476\u001b[0m                                           body=body)\n\u001b[1;32m    477\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"DELETE\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m             return self.rest_client.delete_request(url,\n\u001b[0m\u001b[1;32m    479\u001b[0m                                            \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                                            \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradientai/openapi/client/rest.py\u001b[0m in \u001b[0;36mdelete_request\u001b[0;34m(self, url, headers, query_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    267\u001b[0m     def delete_request(self, url, headers=None, query_params=None, body=None,\n\u001b[1;32m    268\u001b[0m                _preload_content=True, _request_timeout=None):\n\u001b[0;32m--> 269\u001b[0;31m         return self.request(\"DELETE\", url,\n\u001b[0m\u001b[1;32m    270\u001b[0m                             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                             \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradientai/openapi/client/rest.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotFoundException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_resp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m599\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundException\u001b[0m: (404)\nReason: Not Found\nHTTP response headers: HTTPHeaderDict({'strict-transport-security': 'max-age=63072000; includeSubDomains; preload', 'referrer-policy': 'no-referrer', 'x-content-type-options': 'nosniff', 'x-download-options': 'noopen', 'x-frame-options': 'SAMEORIGIN', 'x-xss-protection': '1; mode=block', 'content-type': 'application/json; charset=utf-8', 'etag': '\"cnneatxz1cu\"', 'vary': 'Accept-Encoding', 'X-Cloud-Trace-Context': '82f082f2dff43a19b291a6f5f4147d9a;o=1', 'Date': 'Thu, 11 Apr 2024 03:08:28 GMT', 'Server': 'Google Frontend', 'Content-Length': '30', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\nHTTP response body: {\"message\":\"Model not found.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DcZrq9c4IKdV"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}